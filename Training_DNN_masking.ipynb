{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.16"
    },
    "colab": {
      "name": "Training_DNN_masking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JesusdelCas99/T_H_DNN_Masking/blob/main/Training_DNN_masking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGyid4Q33jxa",
        "outputId": "cb991d92-e583-40ed-8608-d4033ac1731a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNQ7ZgW23xop",
        "outputId": "54d539ed-466e-4962-ed6f-b056aaf01806"
      },
      "source": [
        "#Nos movemos al directorio deseado en google collab\n",
        "%cd '/content/drive/MyDrive/Colab_Notebooks/sigmatools'\n",
        "%ls "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks/sigmatools\n",
            "F05_440C020E_CAF.CH5.noise.wav   F05_440C020E_CAF.CH5.wav  \u001b[0m\u001b[01;34msigmatools\u001b[0m/\n",
            "F05_440C020E_CAF.CH5.speech.wav  setup.py                  \u001b[01;34msigmatools.egg-info\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG1YawCyjzbG"
      },
      "source": [
        "# Preparación de los datos en el nodo para trabajar localmente (adaptar según sea necesario)\n",
        "# !mkdir /tmp/TIMIT_300/\n",
        "# !mkdir /tmp/TIMIT_300/Noises/\n",
        "# !mkdir /tmp/TIMIT_300/Resultados/\n",
        "# !cp -r /home/amgg/Desarrollo/TIMIT_PESQ/TIMIT_300/MONO /tmp/TIMIT_300/\n",
        "# !cp /home/amgg/Desarrollo/TIMIT_PESQ_builder/Noises/*.wav /tmp/TIMIT_300/Noises/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkHeFTOajzbH"
      },
      "source": [
        "####### DEFINICION DE NUESTRA CLASE DATASET (TRATAMIENTO DE LA BASE DE DATOS)\n",
        "\n",
        "#Emplearemos como punto de partida la clase DataSet de Pytorch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Necesitamos algunas librerias para ciertas tareas específicas\n",
        "from scipy.io import wavfile      # Lectura de WAV files\n",
        "import glob                       # Gestion de archivos\n",
        "import os                         # Funciones del SO\n",
        "import pickle                     # Lectura y salvado de objetos en disco\n",
        "\n",
        "\n",
        "class TimitDataset(Dataset):\n",
        "    # Particularizamos la Clase DataSet a nuestras necesidades: podemos añadir nuevos métodos o podemos REDEFINIR\n",
        "    # los ya existentes (lo que se conoce como 'Herencia' en OOP)\n",
        "    \n",
        "    def __init__(self, dir_db, dir_noise, mode='MONO', conj='train'):\n",
        "        # Definimos la inicialización del objeto con los parametros:\n",
        "        #     dir_db   : (string) directorio donde está la base de datos a usar\n",
        "        #     dir_noise: (string) directorio donde está el ruido\n",
        "        #     mode     : (string) subdirectorio de la BB.DD. especifico para experimento\n",
        "        #     conj     : (string) subset de la BB.DD. (train, valid o set) \n",
        "        \n",
        "        #Definicion de los parámetros de la estructura\n",
        "        self.dir_db = dir_db\n",
        "        self.dir_noise = dir_noise\n",
        "        self.mode = mode\n",
        "        self.conj = conj\n",
        "\n",
        "        # Estos datos son fijos para nuestros experimentos (aunque podrían ser tambien parametros, los hemos dejado\n",
        "        # como constantes)\n",
        "        self.snrs = [20, 15, 10, 5, 0, -5]                      # SNRs para el ruido\n",
        "        self.noises = ['CARJA', 'BSTJA', 'PREST', 'STRAF']      # Tipos de ruido\n",
        "        \n",
        "        if self.conj == 'test':                                 # En TEST se añaden tipos de RUIDOS no vistos en Training\n",
        "            #Basicamente hacemos un horzcat en caso de ser un cojunto de test, añadiendo nuevos parametros\n",
        "            self.noises.extend(['PCAFE', 'PSTAT', 'PSTJA', 'TPBUS'])\n",
        "\n",
        "        # Lee y organiza los ficheros de ruido en un diccionario\n",
        "        self.sample_noises = self._get_dict_noises()\n",
        "        \n",
        "        # Obtiene un listado de todos los ficheros '.pkl' que hay en el subset seleccionado (barriendo subdirectorios) \n",
        "        self.lista_files = glob.glob(self.dir_db + self.mode + '/' + self.conj + '/*/*.pkl')\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        # Devuelve el total de número de ficheros en el subset de 'train','valid','set'\n",
        "        return len(self.lista_files)\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        #Construye un diccionario de una sola entrada con el sample a tratar de voz captada con ruido\n",
        "\n",
        "        # Devuelve el 'sample' (ver más abajo) identificado por idx en la lista de ficheros del set\n",
        "        file_meta = self.lista_files[idx]\n",
        "\n",
        "        #Nombre del archivo en cuestion\n",
        "        example_id = os.path.splitext(os.path.basename(file_meta))[0]\n",
        "\n",
        "        # Carga el objeto de metadatos, que indica exactamente como se ha generado la señal de voz noisy del archivo\n",
        "        with open(file_meta, 'rb') as f:\n",
        "            metadata = pickle.load(f)\n",
        "        n_ind = metadata['n_ind']\n",
        "        G = metadata['G_0']\n",
        "        v_norm = metadata['v0_norm']\n",
        "\n",
        "        # Leemos la señal de voz noisy\n",
        "        y = self._read_sample(file_meta[:-4] + '_CH0.wav')  # [:5*16000]\n",
        "\n",
        "        label_noise = example_id.split('_')[2]\n",
        "        n = self.sample_noises[label_noise][n_ind: n_ind + y.shape[0]] * G / v_norm\n",
        "\n",
        "        # Con la información del objeto de metadatos restamos el ruido exacto, obteniendo la señal limpia \n",
        "        x = y - n\n",
        "\n",
        "        # Construimos un \"sample\" de entrenamiento en forma de diccionario con los siguientes datos:\n",
        "        sample = {'example_id': example_id, 'noisy': y, 'clean': x, 'noise': n, 'seq_len': len(y)}\n",
        "\n",
        "        return sample\n",
        " \n",
        "\n",
        "    def _read_sample(self, file_speech):\n",
        "        # Lee el fichero WAV y devuelve un vector con sus muestras\n",
        "        time_signal = wavfile.read(file_speech)[1] * 1.0\n",
        "        return time_signal #Nos quedamos con el canal derecho\n",
        "\n",
        "\n",
        "    def _get_dict_noises(self):\n",
        "        # Organiza las muestras de ruido\n",
        "        # Construye un diccionario con las muestras de los ruidos. El nombre de archivo identifica el tipo de ruido \n",
        "        # y el subset al que se debe aplicar (Training, Validacion, Test).\n",
        "        \n",
        "        sample_noises = dict() #Inicializamos el diccionario\n",
        "        \n",
        "        # Para saber que fichero hay que leer, debemos traducir el conjunto que queremos (e.g. 'train'->ficheros 'T')\n",
        "        if self.conj == 'train':\n",
        "            id_conj = 'T'\n",
        "        elif self.conj == 'valid':\n",
        "            id_conj = 'V'\n",
        "        elif self.conj == 'test':\n",
        "            id_conj = 'E'\n",
        "        else:\n",
        "            raise ValueError('Unexpected subset')\n",
        "\n",
        "        for noise in self.noises:\n",
        "            # Para cada uno de los noises (['CARJA', 'BSTJA', 'PREST',...]) lee el fichero WAV y guarda los datos \n",
        "            # en un diccionario en donde el id es el nombre del ruido\n",
        "            noise_id = noise + '_' + self.mode + '_' + id_conj #Por ejemplo noise_id=CARJA_MONO_T\n",
        "            n = self._read_sample(self.dir_noise + noise_id + '_CH1.wav') #Leemos el ruido de un determinado fichero\n",
        "            sample_noises.update({noise: n})\n",
        "\n",
        "        return sample_noises"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHWj4UYxjzbH"
      },
      "source": [
        "####### CONSTRUCCION DE NUESTRA (CLASE DE) RED NEURONAL\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Esta es una libreria propia con funciones diversas, de ella importamos las funciones para\n",
        "# construir una ventana de hamming, calcular una transformada corta de Fourier y su inversa (síntesis)\n",
        "from sigmatools.transform.stft_fn import stft, istft\n",
        "from sigmatools.transform.window import hann_sqrt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Primero construimos una clase generica de red neuronal orientada al Procesamiento de Voz y capaz de usar nuestro\n",
        "# dataset (el que hemos definido antes)\n",
        "class _base_net(nn.Module):\n",
        "    # Aqui PARTICULARIZAMOS la clase nn.Module proporicionada por pytorch para la construcción de DNNs. \n",
        "    \n",
        "    #Constructor\n",
        "    def __init__(self, opt):\n",
        "        # Definimos la inicialización de la DNN mediante un objeto de opciones (al poder ser muy distintas y\n",
        "        # variadas las opciones que necesitemos, pasamos directamente un objeto que dará esta informacion)\n",
        "        \n",
        "        # IMPORTANTE, a diferencia de la clase DataSet, la clase Module tiene ya un INIT (para inicializar las \n",
        "        # 'tripas' de la red neuronal que ni nos importan ni nos interesan). Por eso llamamos aqui a la inicialización\n",
        "        # de la clase padre (o superclase)\n",
        "\n",
        "        #Importamos los parametros de la clase nn.Module\n",
        "        super(_base_net, self).__init__()\n",
        "\n",
        "        # Establecemos los atributos que toda DNN orientada al procesado de voz (tal y como lo vamos a hacer\n",
        "        # nososotros, con STFT) debe de tener. Basicamente definimos los parámetros de la STFT\n",
        "        \n",
        "        self.window_length = opt.window_length                   # Tamaño de la ventana (tramas) empleada para la STFT\n",
        "        self.shift = opt.shift                                   # Desplazamiento de ventanas (entre frames)\n",
        "        self.window = hann_sqrt(self.window_length, self.shift)  # Ventana de analisis empleada para la STFT\n",
        "        self.hidden_units = opt.hidden_units                     # Numero de unidades ocultas por capa (Numero de neuronas por capa)\n",
        "        self.dropout_rate = opt.dropout_rate                     # Dropout rate a emplear en el entrenamiento\n",
        "\n",
        "    \n",
        "    def collate_fn(self, input_batch):\n",
        "        # Definicion del batch\n",
        "\n",
        "        # Toda DNN que construyamos debe ser capaz de proveer de una función para la carga de un batch de 'samples' \n",
        "        # de entrenamiento acorde a sus propias necesidades.\n",
        "        \n",
        "        # Recordemos cómo era un sample del dataset (clase anterior):\n",
        "        #  # Construimos un \"sample\" de entrenamiento en forma de diccionario con los siguientes datos:\n",
        "        #  sample = {'example_id': example_id, 'noisy': y, 'clean': x, 'noise': n, 'seq_len': len(y)}\n",
        "        \n",
        "        # Mas adelante veremos que pytorch prepara en paralelo (en la CPU, mientras la GPU está ocupada\n",
        "        # entrenando la red neuronal con un batch) los datos del siguiente batch. Esta función le indica como\n",
        "        # debe hacerse esta preparación (que no depende de los datos, sino de como hayamos diseñado nuestra DNN). \n",
        "        \n",
        "        # El parametro input_bach no es más que una lista de 'sample' anteriores\n",
        "        \n",
        "        \n",
        "        # Construimos tres listas para cada una de la informacion que nos interesa (ie. toda menos el 'example_id')\n",
        "        list_seq_len = [item['seq_len'] for item in input_batch]     # Lista longitudes de las señales del batch\n",
        "        list_clean = [item['clean'] for item in input_batch]         # Lista de vectores con señales limpias\n",
        "        list_noisy = [item['noisy'] for item in input_batch]         # Lista de vectores con señales noisy\n",
        "\n",
        "        \n",
        "        # A partir de aqui lo que hacemos es construir el batch de entrenamiento a partir de las listas anteriore\n",
        "        # (en el fondo a partir de la lista de 'samples' que hemos recibido a la entrada)\n",
        "        seq_len = np.array(list_seq_len)\n",
        "\n",
        "        # Padding para que todas las señales tengan la misma longitud\n",
        "        max_length = np.amax(seq_len)\n",
        "        clean_pad = np.stack([np.pad(item, (0, max_length - len(item)), 'constant') for item in list_clean])\n",
        "        noisy_pad = np.stack([np.pad(item, (0, max_length - len(item)), 'constant') for item in list_noisy])\n",
        "\n",
        "        # Calculo de la STFT (Magnitud)\n",
        "        #ToDO: Calcular la STFT y su valor absoluto para voz limpia y ruidosa (variables clean y noisy)\n",
        "        STFT_clean=abs(stft(clean_pad,self.window,size=self.window_length,shift=self.shift))\n",
        "\n",
        "        STFT_noisy=abs(stft(noisy_pad,self.window,size=self.window_length,shift=self.shift))\n",
        "\n",
        "        # Calculo de log-spectra\n",
        "        #ToDo: Calcular el logritmo del espectro (cuidado con valores a cero) y aplicar normalizacion recursiva (mas abajo)\n",
        "        delta=1e-12\n",
        "        noisy_lps=np.log(STFT_noisy+delta)\n",
        "\n",
        "        noisy_lps_norm=self.rec_mean_normalization(noisy_lps)\n",
        "        \n",
        "        frame_len = self.sample_to_frame(seq_len) #Numero de ventanas para cada señal dentro del batch\n",
        "\n",
        "        pad_mask = np.zeros((noisy_lps.shape[0], noisy_lps.shape[1], 1))\n",
        "        for idx in range(len(frame_len)):\n",
        "            pad_mask[idx, :frame_len[idx]] = 1.0\n",
        "\n",
        "        # Construcción del batch 'a huevo' para que lo use la DNN\n",
        "        output_batch = {'features': torch.from_numpy(noisy_lps_norm).float(),\n",
        "                        'pad_mask': torch.from_numpy(pad_mask).float(),\n",
        "                        'noisy': torch.from_numpy(STFT_noisy).float(),\n",
        "                        'clean': torch.from_numpy(STFT_clean).float()}\n",
        "\n",
        "        return output_batch\n",
        "    \n",
        "    #ToDo: Crear una funcion collate similar, pero para usarla en test (i.e. simplificado y para un solo elemento)\n",
        "    # ver ejercicio final\n",
        "\n",
        "    # Resto de funciones auxiliares implicadas en la construccion de un batch:\n",
        "    def sample_to_frame(self, nsample):\n",
        "        #Note: This function assumes there is fading in the STFT computation --- NO ENTIENDO\n",
        "        nframe = np.int_(np.ceil((((nsample - self.window_length) * 1.0) / self.shift)) + 3) * np.array([1])\n",
        "        return nframe\n",
        "\n",
        "\n",
        "    def istft(self, enh_stft, seq_len):\n",
        "        #ToDo: Definir la ISTFT\n",
        "        enh_signal = istft(enh_stft, self.window, signal_length=seq_len, size=self.window_length, shift=self.shift)\n",
        "        return enh_signal\n",
        "\n",
        "\n",
        "    def rec_mean_normalization(self, Y):\n",
        "        # Create vector to save result and mean\n",
        "        #ToDo: Un vector donde guardar ls resutlados y otro para ir almancenando la media (mirar zeros_like)\n",
        "        # Señal Y tiene 3 dimensiones; batch, tiempo y frecuencia (nos interesa el tiempo)\n",
        "        Y_norm = np.zeros_like(Y)\n",
        "        means = np.copy(Y_norm[:,0,:])\n",
        "        # Recursive mean computation and subtraction\n",
        "        for t in range(Y.shape[1]):\n",
        "            #ToDo: Calcular la media recursiva en cada frame (a partir de la media anterior y el valor actual)\n",
        "            #ToDo: Sustraer la media en el instante actual\n",
        "            means = t/(t+1.0) * means + 1.0/(t+1.0) * Y[:,t,:]\n",
        "            Y_norm[:,t,:] = Y[:,t,:] - means\n",
        "        return Y_norm\n",
        "    ##########################\n",
        "    \n",
        "\n",
        "\n",
        "# Ahora construimos nuestra DNN particular, con su propia estructura. En este caso vamos a definir una red\n",
        "# sencilla de tipo Feed-Forward con tres capas ocultas fully-connected y una ultima capa de salida\n",
        "class DNN_ENH(_base_net):\n",
        "\n",
        "    def __init__(self, opt):\n",
        "        # De nuevo, llamada al INIT de la superclase (padre), en donde establecíamos los atributos orientados\n",
        "        # al procesado de voz\n",
        "\n",
        "        #Herencia de clases\n",
        "        super(DNN_ENH, self).__init__(opt)\n",
        "\n",
        "        # Computo de dimensiones del input y del target\n",
        "        self.input_dim = (opt.window_length/2)+1 #ToDo (Numero de puntos del espectro)\n",
        "        self.target_dim = self.input_dim #ToDo\n",
        "        self.hidden_layer_size=opt.hidden_units\n",
        "        \n",
        "        # Construcción de las capas mediante primitivas de la libreria nn de pytorch \n",
        "        # Alternativamente podríamos usar tensores con el cómputo del gradiente activado\n",
        "        \n",
        "        #ToDo: Dos capas LSTM, luego una capa oculta y la capa final (mirar lstm y Linear)\n",
        "        self.LSTM=nn.LSTM(self.input_dim, self.hidden_layer_size, 2,batch_first=True,dropout=opt.dropout_rate)\n",
        "        self.linear_oculta=nn.Linear(self.hidden_layer_size, self.hidden_layer_size)\n",
        "        self.fc_end=nn.Linear(self.hidden_layer_size,self.target_dim)\n",
        "    \n",
        "        # Capa de dropout (esto si que es mejor que se encarge pytorch)\n",
        "        #ToDO\n",
        "        self.drop_layer = nn.Dropout(p=opt.dropout_rate)\n",
        "            \n",
        "    # En toda clase DNN de pytorch siempre hay que definir el método \"forward\" que expresa como se \n",
        "    # convierte la entrada en la salida de la red.\n",
        "    # Este método es llamado automaticamente por el optimizador de la red\n",
        "    def forward(self, x):\n",
        "        \n",
        "        #ToDo: ir operando con el vector x y las capas hasta obtener la máscara de salida (vamos redefiniendo x)\n",
        "        #Nota: Dropout a la salida de todas las capas menos la ultima. ReLu para la capa oculta y sigmoide para la final\n",
        "        x, _=self.LSTM(x)\n",
        "        x=self.drop_layer(x)\n",
        "        x=self.drop_layer(F.sigmoid(self.linear_oculta(x)))\n",
        "        x=F.sigmoid(self.fc_end(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V5s6l5_jzbH"
      },
      "source": [
        "####### FUNCIÓN DE PÉRDIDA\n",
        "\n",
        "# Aunque podría integrarse dentro de la DNN, es conventiente sacar fuera la función de coste, especialmente si\n",
        "# queremos testear distintos tipos de ellas\n",
        "class mse_loss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "      # Debe notarse como esta clase hereda de 'nn.Module' como si fuera una especie de red neuronal.\n",
        "      # De hecho, como tal, le especificamos un método forward\n",
        "      #Importamos los parametros de la clase nn.Module\n",
        "      super(mse_loss, self).__init__()\n",
        "      self.MSE=nn.MSELoss(size_average=None, reduce=None, reduction='none')\n",
        "\n",
        "      #Si lo aplicamos elemento a elemento y no realizamos media, sigue siendo MSE??\n",
        "\n",
        "    def forward(self, output, target, pad_mask):\n",
        "        # Simplemente calcula el MSE entre output y target considerando la máscara de pading (la que usamos para\n",
        "        # hacer todas las señales del batch del mismo tamaño)\n",
        "        \n",
        "        loss_element = self.MSE(output, target)\n",
        "        loss_sum = torch.sum(loss_element*pad_mask) #ToDo: Enmascarar con el pad_mask y sumar los elementos\n",
        "        loss = loss_sum/(torch.sum(pad_mask) * len(loss_sum[0,0,:])) #ToDo: Promediar por el numero de elementos utiles (descartar el padding)\n",
        "        return loss\n",
        "\n",
        "loss_function = mse_loss()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw0bX417jzbH"
      },
      "source": [
        "####### OPTIMIZADOR\n",
        "\n",
        "# Pytorch integra un buen número de optimizadores que podemos importar\n",
        "import torch.optim as optim\n",
        "\n",
        "# El optmizador se aplica sobre una lista de tensores que queremos optimizar, en nuestro caso, esta lista se\n",
        "# compone de los parametros de nuestra DNN. Por tanto, vamos a instanciar nuestra clase FFN_CTX generando un objeto\n",
        "# (la red DNN que vamos a entrenar).\n",
        "\n",
        "# Lo primero que haremos será establecer las opciones de nuestro experimento. Esto generalmente lo haremos mediante\n",
        "# parametros en la linea de ordenes al llamar al script de python, empleando la libreria 'util.parse_args' para\n",
        "# procesarlos. Esta librería genera directamente el objeto, que aqui replicaremos a mano de esta forma:\n",
        "class Opt:\n",
        "    def __init__(self):\n",
        "        self.window_length = 512\n",
        "        self.shift = 256\n",
        "        self.hidden_units = 1024\n",
        "        self.dropout_rate = 0.5\n",
        "        self.early_stop = 20\n",
        "\n",
        "opt = Opt();\n",
        "\n",
        "# Con esas opciones instanciamos la red\n",
        "estimator = DNN_ENH(opt)\n",
        "\n",
        "# Construyendo finalmente el optimizador (que se aplica sobre los parametros de la red)\n",
        "optimizer = optim.Adam(estimator.parameters())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcnWrIsfjzbI"
      },
      "source": [
        "####### ENTRENAMIENTO DE LA RED\n",
        "#####.    1- DataLoaders\n",
        "\n",
        "# Lo primero que hacemos es preparar un DataLoader. Estos objetos nos permiten paralelizar el trabajo: mientras la GPU\n",
        "# está ocupada haciendo los pasos forward y backward sobre la DNN con el batch actual, la CPU esta leyendo del disco\n",
        "# y procesando los datos del siguiente batch.\n",
        "# Pytorch se encarga del trabajo sucio, tan solo hay que pasar a DataLoader un dataset compatible (esencialmente con\n",
        "# métodos de inicializacion, devolución de tamaño y de samples como los que hemos definido nuestro 'TimitDataset') y\n",
        "# un método de construcción de batches compatibles con la red a partir de samples (como el que definimos en nuestra\n",
        "# DNN '_base_net') \n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Datasets de training y validación\n",
        "timit_set_train = TimitDataset('../Base_de_datos/Base_datos_1/TIMIT_300/', '../Base_de_datos/Base_datos_2/Noises/', mode='MONO', conj='train')\n",
        "timit_set_valid = TimitDataset('../Base_de_datos/Base_datos_1/TIMIT_300/', '../Base_de_datos/Base_datos_2/Noises/', mode='MONO', conj='valid')\n",
        "\n",
        "# DataLoaders de training y validación\n",
        "# Notese como llamamos al método 'collate_fn' que el objeto 'estimator' de la clase 'FFN_CTX' ha heredado de su clase\n",
        "# padre '_base_net'\n",
        "train_dataloader = DataLoader(timit_set_train, batch_size=10, shuffle=True, num_workers=5,\n",
        "                            collate_fn=estimator.collate_fn)\n",
        "valid_dataloader = DataLoader(timit_set_valid, batch_size=1, shuffle=False, num_workers=5,\n",
        "                            collate_fn=estimator.collate_fn)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UO3f6tajzbI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "5b710a1f-9129-47f3-ce03-73c70b8bf2d5"
      },
      "source": [
        "####### ENTRENAMIENTO DE LA RED\n",
        "#####.    2- Bucle de optimización\n",
        "\n",
        "# Antes de nada, vamos a mandar a la GPU (si está disponible) la DNN y la función de coste:\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "estimator.to(device)\n",
        "loss_function.to(device)\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "# Comenzamos el entrenamiento:\n",
        "\n",
        "print(\"[*] Start training...\")\n",
        "num_batch_train = len(train_dataloader)\n",
        "num_batch_valid = len(valid_dataloader)\n",
        "\n",
        "num_epochs = 200\n",
        "save_net = 'model_best.pth.tar'\n",
        "\n",
        "strike = 0\n",
        "old_mean_val_distortion = 1e100\n",
        "\n",
        "# Training epochs\n",
        "for epoch in xrange(num_epochs):\n",
        "\n",
        "    # Ciertas capas (como las de dropout, batch_normalization, etc.) se comportan de distinta forma\n",
        "    # si estamos entrenando la red, o si estamos evaluandola. Para activar el comportamiento adecuado\n",
        "    # se emplean los métodos 'train' y 'eval' de la clase 'nn.Module'\n",
        "    \n",
        "    estimator.train()\n",
        "    \n",
        "    avg_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for id, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Transferimos los tensores de la CPU a la GPU para realizar el entrenamiento\n",
        "        features = batch['features'].to(device)\n",
        "        noisy = batch['noisy'].to(device)\n",
        "        target = batch['clean'].to(device)\n",
        "        pad_mask = batch['pad_mask'].to(device)\n",
        "\n",
        "        # Puesto que el entrenamiento requiere de backpropagation, es necesario que todos los tensores\n",
        "        # activen sus gradientes. Para no tener que ir uno por uno activamos un contexto de python:\n",
        "        with torch.set_grad_enabled(True): \n",
        "\n",
        "            # Reseteamos los gradientes a 0 (si no se acumularían los nuevos sobre los de la iteracion anterior)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            output_mask = estimator(features)\n",
        "            output = output_mask * noisy\n",
        "\n",
        "            loss = loss_function(output, target, pad_mask)\n",
        "            avg_loss += loss.item() / num_batch_train\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Print loss in the epoch\n",
        "    print_line = \"Epoch: [%2d] time: %4.4f, loss: %.4f\" % (epoch + 1, time.time() - start_time, avg_loss)\n",
        "    print(print_line)\n",
        "\n",
        "    # Acabada una época, vamos a ver el rendimiento de la red sobre el conjunto de evaluación\n",
        "    # Ponemos las capas necesarias en modo 'evaluación'\n",
        "    estimator.eval()\n",
        "    \n",
        "    valid_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for id, batch in enumerate(valid_dataloader):\n",
        "\n",
        "        # Transferimos los tensores de la CPU a la GPU para realizar el entrenamiento\n",
        "        features = batch['features'].to(device)\n",
        "        noisy = batch['noisy'].to(device)\n",
        "        target = batch['clean'].to(device)\n",
        "        pad_mask = batch['pad_mask'].to(device)\n",
        "\n",
        "        # Puesto que NO vamos a backpropagar con estos datos, podemos deshabilitar el cómputo de gradientes\n",
        "        # mejorando el rendimiento\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass\n",
        "            output_mask = estimator(features)\n",
        "            output = output_mask * noisy\n",
        "\n",
        "            loss = loss_function(output, target, pad_mask)\n",
        "            valid_loss += loss.item() / num_batch_valid\n",
        "\n",
        "    # Implementamos un mecanismo de Early-Stopping\n",
        "    if (valid_loss < old_mean_val_distortion):\n",
        "        # Si hemos mejorado el entrenamiento, reseteamos el contador de strikes y guardamos el modelo\n",
        "        print_line = \"     Valid: time: %4.4f, valid_loss: %.4f\" % (time.time() - start_time, valid_loss)\n",
        "        print(print_line)\n",
        "        old_mean_val_distortion = valid_loss\n",
        "        strike = 0\n",
        "\n",
        "        # Save the model\n",
        "        print(\"[*] Saving model epoch %d...\" % (epoch + 1))\n",
        "        state = {'epoch': epoch + 1, 'state_dict': estimator.state_dict(), 'optimizer': optimizer.state_dict(),\n",
        "                     'train_loss': avg_loss, 'eval_loss': valid_loss}\n",
        "        torch.save(state, save_net)\n",
        "\n",
        "    else:\n",
        "        # Si NO hemos mejorado el entrenamiento, incrementamos el contador de strikes\n",
        "        strike += 1\n",
        "\n",
        "        print_line = \"     Valid: time: %4.4f, valid_loss: %.4f *\"  % (time.time() - start_time, valid_loss)\n",
        "        print(print_line)\n",
        "        # Tras un cierto numero de strikes (también llamado 'patience'), finalizamos el entrenamiento\n",
        "        if strike > opt.early_stop:\n",
        "            break\n",
        "\n",
        "\n",
        "print(\"[*] Finish training.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*] Start training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9a1b26cb5e1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_mask\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoisy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_batch_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-6a3352bda902>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output, target, pad_mask)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_element\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpad_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#ToDo: Enmascarar con el pad_mask y sumar los elementos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_sum\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#ToDo: Promediar por el numero de elementos utiles (descartar el padding)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxsnsJKWjzbI"
      },
      "source": [
        "# Ejercicio final: Implementar un procedimiento de test de la red ya entrenada.\n",
        "# Evaluar con una métrica objetiva (ya lo vemos mas adelante cuando este todo lo anterior listo)\n",
        "\n",
        "# Ayuda para cargar red ya entrenada en el estimador (model_load es el fichero donde tenemos los parametros)\n",
        "#checkpoint = torch.load(model_load)\n",
        "#estimator.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}